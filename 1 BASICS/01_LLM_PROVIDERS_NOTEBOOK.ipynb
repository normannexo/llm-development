{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Providers Integration Notebook\n",
    "\n",
    "## Purpose\n",
    "This notebook serves as a comprehensive guide and code repository for integrating with various Large Language Model (LLM) providers. It demonstrates how to set up, configure, and utilize different LLM APIs in your Python projects.\n",
    "\n",
    "## What's Included\n",
    "- **Code examples** for major LLM providers (OpenAI, Anthropic, Mistral AI, etc.)\n",
    "- **Authentication setup** with environment variables\n",
    "- **Basic prompting techniques** for different model architectures\n",
    "- **Response handling** and parsing strategies\n",
    "- **Comparison of capabilities** across different providers\n",
    "\n",
    "## How to Use\n",
    "Each section contains ready-to-use code snippets that you can adapt for your own applications. Simply ensure you have the appropriate API keys configured in your environment variables.\n",
    "\n",
    "## Getting Started\n",
    "Make sure you have installed all required dependencies from the [requirements.txt](cci:7://file:///c:/Users/norma/OneDrive/Dokumente/Development/git/llm-development/requirements.txt:0:0-0:0) file and set up your API keys in a `.env` file before running the examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISTRAL\n",
    "\n",
    "DOCS https://docs.mistral.ai/getting-started/quickstart/ \\\n",
    "\\\n",
    "AVAILABLE MODELS: https://docs.mistral.ai/getting-started/models/models_overview/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISTRAL\n",
    "from mistralai import Mistral\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "model = \"mistral-large-latest\"\n",
    "\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "chat_response = client.chat.complete(\n",
    "    model= model,\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the best French cheese?\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIXTRAL\n",
    "\n",
    "URL https://docs.mistral.ai/capabilities/vision/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MISTRAL PIXTRAL WITH IMAGE URL\n",
    "\n",
    "import os\n",
    "from mistralai import Mistral\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API key from environment variables\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "\n",
    "# Specify model\n",
    "model = \"pixtral-12b-2409\"\n",
    "\n",
    "# Initialize the Mistral client\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "# Define the messages for the chat\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"What's in this image?\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": \"https://tripfixers.com/wp-content/uploads/2019/11/eiffel-tower-with-snow.jpeg\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Get the chat response\n",
    "chat_response = client.chat.complete(\n",
    "    model=model,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Print the content of the response\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISTRAL PIXTRAL WITH BASE64 ENCODED IMAGE\n",
    "\n",
    "import base64\n",
    "import requests\n",
    "import os\n",
    "from mistralai import Mistral\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"Encode the image to base64.\"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {image_path} was not found.\")\n",
    "        return None\n",
    "    except Exception as e:  # Added general exception handling\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Path to your image\n",
    "os.chdir(\"../..\")  # Navigate up two levels to the project root\n",
    "image_path = \"./DATA/EXAMPLEFILES/IMAGE/chess_position.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "# Retrieve the API key from environment variables\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "\n",
    "# Specify model\n",
    "model = \"pixtral-12b-2409\"\n",
    "\n",
    "# Initialize the Mistral client\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "# Define the messages for the chat\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"What's in this image?\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": f\"data:image/jpeg;base64,{base64_image}\" \n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Get the chat response\n",
    "chat_response = client.chat.complete(\n",
    "    model=model,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Print the content of the response\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "from mistralai import Mistral\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def encode_image(image_path):\n",
    "    \"\"\"Encode the image to base64.\"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {image_path} was not found.\")\n",
    "        return None\n",
    "    except Exception as e:  # Added general exception handling\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "# Path to your image\n",
    "image_path = \"path_to_your_image.jpg\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "ocr_response = client.ocr.process(\n",
    "    model=\"mistral-ocr-latest\",\n",
    "    document={\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": f\"data:image/jpeg;base64,{base64_image}\" \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANTHROPIC\n",
    "\n",
    "url https://docs.anthropic.com/claude/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelInfo(id='claude-3-7-sonnet-20250219', created_at=datetime.datetime(2025, 2, 24, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude 3.7 Sonnet', type='model'),\n",
       " ModelInfo(id='claude-3-5-sonnet-20241022', created_at=datetime.datetime(2024, 10, 22, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude 3.5 Sonnet (New)', type='model'),\n",
       " ModelInfo(id='claude-3-5-haiku-20241022', created_at=datetime.datetime(2024, 10, 22, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude 3.5 Haiku', type='model'),\n",
       " ModelInfo(id='claude-3-5-sonnet-20240620', created_at=datetime.datetime(2024, 6, 20, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude 3.5 Sonnet (Old)', type='model'),\n",
       " ModelInfo(id='claude-3-haiku-20240307', created_at=datetime.datetime(2024, 3, 7, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude 3 Haiku', type='model'),\n",
       " ModelInfo(id='claude-3-opus-20240229', created_at=datetime.datetime(2024, 2, 29, 0, 0, tzinfo=datetime.timezone.utc), display_name='Claude 3 Opus', type='model')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ANTHROPIC GET MODELS\n",
    "\n",
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "client.models.list(limit=20).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANTHROPIC SIMPLE INTERACTION\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (assuming you have an API key stored in .env)\n",
    "load_dotenv()\n",
    "\n",
    "response = Anthropic(api_key=os.environ.get(\"ANTHROPIC_API_KEY\")).messages.create(\n",
    "    model=\"claude-3-7-sonnet-20250219\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, Claude\"}\n",
    "    ]\n",
    ")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
